import re
from googletrans import Translator



# text ='''
# DB: ğŸŒ€FULL SCHOLARSHIP AVAILABLE IN; ğŸ‡¨ğŸ‡³CHINA ğŸ‡¨ğŸ‡¦ CANADA ğŸ‘ğŸ‘ğŸ‘ChinağŸ‡¨ğŸ‡³ğŸ‡¨ğŸ‡³ ğŸ’ŒX2 visa without classes ( you don't have to exit) ğŸ’ŒTourist L visa ğŸ’ŒBusiness M visa ğŸ’ŒWorking Z visa . 1 year ğŸ’ŒFamily Q or S visa 30 days ğŸ’ŒVisa On Arrival 30 days ğŸ‘ğŸ‘ğŸ‘CandağŸ‡¨ğŸ‡¦ğŸ‡¨ğŸ‡¦ ğŸ’ŒPermanent Residence visa ğŸ’ŒWork permit and visa ğŸ’ŒStudy permit and visa â‡ï¸DIPLOMAâ‡ï¸BACHELORâ‡ï¸MASTERSâ‡ï¸PHD STUDENTS ğŸ›‘UNIVERSITIES IN CANADA â‡ï¸University Of Alberta â‡ï¸University Of Toronto â‡ï¸University Of Waterloo â‡ï¸Mcgill University â‡ï¸Queen University â‡ï¸York University ğŸ›‘UNIVERSITIES IN CHINA â‡ï¸Wuhan University â‡ï¸Shanghai university â‡ï¸Jiangxi University â‡ï¸Guizhou University â‡ï¸Henan University â‡ï¸Hebei University ğŸ›‘SCHOLARSHIP COVERS TUITION AND ACCOMMODATION FREE WITH MONTHLY ALLOWANCE, HEALTH INSURANCE AND VISA ASSISTANCE â‡ï¸ENGLISH TAUGHT Admission Notice within 14days and JW202 within 14 days #Aged 18-45 Deadline: As Seats Full..!!ğŸš« ğŸ’¯ confirmed[OK] ğŸˆ´ Certificate purchase ğŸˆ´HSK 1-5 NON APPEARANCE ğŸˆ´IELTS CERTIFICATE ğŸˆ´TESOL ğŸˆ´TEfL ğŸˆ´CELTS ğŸˆ´GMAT ğŸˆ´MCAT ğŸˆ´PSGE ğŸˆ´PU INVITATION LETTER ğŸˆ´TE INVITATION LETTER ğŸˆ´OVERSTAY CLEARANCE For More Details Contact us 
# '''



MIN_CHINESE_CHAR_COUNT = 10
MIN_WORD_COUNT = 12

def do_word_count(text):
    # [ Word Count **Met**, Translate]
 
    if re.search(u'[\u4e00-\u9fff]', text):
        print('Its Chinese')
        print(f'WORD LEN: {len(text)}')
        return [False, True] if len(text) > MIN_CHINESE_CHAR_COUNT else [True, True]
        
    word_count = len(text.strip().split(' '))
    print(f'WORD LEN: {word_count}')

    # if re.search('[Ğ°-ÑĞ-Ğ¯]', text):
    try:
    # False positive if they use emojis and icons
        text.encode().decode('ascii')
        return [False, False] if word_count > MIN_WORD_COUNT else [True, False]
    except UnicodeDecodeError:
        print('Its NOT English')
        return [False, True] if word_count > MIN_WORD_COUNT else [True, True]
            
        



def text_parser(text):

    text = text.lower() 

    lang_check = do_word_count(text)
    trans = ''

    if lang_check[0]:
        print(f'Text: {text}')
        print(f'TEXT TOO SHORT!!')
        return ['Not Long Enough', '', '', '', '']


    if lang_check[1]:
        translator = Translator()
        trans = translator.translate(text).text
        print(trans)
   

    # Check for cities
    py_cities = (r'an\s?kang', r'an\s?qing', r'an\s?shan', r'an\s?shun', r'an\s?yang', r'bai\s?cheng', r'bai\s?se', r'bai\s?shan', r'bai\s?yin', r'bao\s?ding', r'bao\s?ji', r'bao\s?shan', r'bao\s?tou', r'bayannur', r'ba\s?zhong', r'bei\s?hai', r'bei\s?jing', r'beng\s?bu', r'ben\s?xi', r'bin\s?zhou', r'bortala', r'bo\s?zhou', r'cang\s?zhou', r'chang\s?chun', r'chang\s?de', r'chang\s?sha', r'chang\s?zhi', r'chang\s?zhou', r'chao\s?hu', r'chao\s?zhou', r'cheng\s?de', r'cheng\s?du', r'chen\s?zhou', r'chiayi', r'chi\s?feng', r'chi\s?zhou', r'chong\s?qing', r'chong\s?zuo', r'chu\s?zhou', r'da\s?lian', r'dan\s?dong', r'da\s?qing', r'da\s?tong', r'da\s?zhou', r'de\s?yang', r'de\s?zhou', r'ding\s?xi', r'dong\s?guan', r'dong\s?ying', r'en\s?shi', r'e\s?zhou', r'fang\s?cheng\s?gang', r'fo\s?shan', r'fu\s?shun', r'fu\s?xin', r'fu\s?yang', r'fu\s?zhou', r'gan\s?zhou', r"guang'an", r'guang\s?yuan', r'guang\s?zhou', r'gui\s?gang', r'gui\s?lin', r'gui\s?yang', r'gu\s?yuan', r'hai\s?kou', r'hami', r'han\s?dan', r'hang\s?zhou', r'han\s?zhong', r'harbin', r'ha\s?er\s?bin', r'he\s?bi', r'he\s?chi', r'he\s?fei', r'he\s?gang', r'hei\s?he', r'heng\s?shui', r'heng\s?yang', r'he\s?yuan', r'he\s?ze', r'he\s?zhou', r'hohhot', r'hu\s?he\s?hao\s?te', r'hong kong', r'hsinchu', r"huai'an", r'huai\s?bei', r'huai\s?hua', r'huai\s?nan', r'huang\s?gang', r'huang\s?shan', r'huang\s?shi', r'hui\s?zhou', r'hu\s?lu\s?dao', r'hulunbuir', r'hu\s?zhou', r"ji'an", r'jia\s?ge\s?da\s?qi', r'jia\s?mu\s?si', r'jiang\s?men', r'jiao\s?zuo', r'jia\s?xing', r'jia\s?yu\s?guan', r'jie\s?yang', r'ji\s?lin', r'ji\s?nan', r'jin\s?chang', r'jin\s?cheng', r'jing\s?de\s?zhen', r'jing\s?men', r'jing\s?zhou', r'jin\s?hua', r'ji\s?ning', r'jin\s?zhong', r'jin\s?zhou', r'jiu\s?jiang', r'jiu\s?quan', r'ji\s?xi', r'ji\s?yuan', r'kai\s?feng', r'kaohsiung', r'karamay', r'kashi', r'kashgar', r'keelung', r'kun\s?ming', r'kun\s?shan', r'lai\s?bin', r'lai\s?wu', r'lang\s?fang', r'lan\s?zhou', r'le\s?shan', r'lhasa', r'lian\s?yun\s?gang', r'liao\s?cheng', r'liao\s?yang', r'liao\s?yuan', r'li\s?jiang', r'lin\s?cang', r'lin\s?fen', r'linxia hui', r'lin\s?yi', r'li\s?shui', r'liu\s?pan\s?shui', r'liu\s?zhou', r'long\s?nan', r'long\s?yan', r'lou\s?di', r"lu'an", r'luo\s?he', r'luo\s?yang', r'lu\s?zhou', r'lv\s?liang', r"ma'anshan", r'macao', r'mao\s?ming', r'mei\s?shan', r'mei\s?zhou', r'mian\s?yang', r'mu\s?dan\s?jiang', r'nagqu', r'nan\s?chang', r'nan\s?chong', r'nan\s?jing', r'nan\s?ning', r'nan\s?ping', r'nan\s?tong', r'nan\s?yang', r'nei\s?jiang', r'ngari area', r'ning\s?bo', r'ning\s?de', r'nyingchi prefecture', r'ordos', r'er\s?duo\s?si', r'pan\s?jin', r'pan\s?zhi\s?hua', r'ping\s?ding\s?shan', r'ping\s?liang', r'ping\s?xiang', r'ping\s?xiang', r"pu'er", r'pu\s?tian', r'pu\s?yang', r'qamdo', r'qian\s?jiang', r'qing\s?dao', r'qing\s?yang', r'qing\s?yuan', r'qin\s?huang\s?dao', r'qin\s?zhou', r'qiong\s?hai', r'qi\s?qi\s?har', r'qi\s?tai\s?he', r'quan\s?zhou', r'qu\s?jing', r'qu\s?zhou', r'ri\s?zhao', r'san\s?men\s?xia', r'san\s?ming', r'san\s?ya', r'shang\s?hai', r'shang\s?luo', r'shang\s?qiu', r'shang\s?rao', r'shan\s?nan', r'shan\s?tou', r'shan\s?wei', r'shao\s?guan', r'shao\s?xing', r'shao\s?yang', r'shen\s?yang', r'shen\s?zhen', r'shi\s?jia\s?zhuang', r'shi\s?yan', r'shi\s?zui\s?shan', r'shuang\s?ya\s?shan', r'shuo\s?zhou', r'si\s?ping', r'song\s?yuan', r'sui\s?hua', r'sui\s?ning', r'sui\s?zhou', r'su\s?qian', r'su\s?zhou', r'tacheng', r"tai'an", r'taichung', r'tai\s?nan', r'taipei', r'tai\s?yuan', r'tai\s?zhou', r'tang\s?shan', r'tian\s?jin', r'tian\s?shui', r'tibet', r'tie\s?ling', r'tong\s?chuan', r'tong\s?hua', r'tong\s?liao', r'tong\s?ling', r'turpan', r'ulanqab', r'urumqi', r'wu\s?lu\s?mu\s?qi', r'wei\s?fang', r'wei\s?hai', r'wei\s?nan', r'wen\s?chang', r'wen\s?zhou', r'wu\s?hai', r'wu\s?han', r'wu\s?hu', r'wu\s?wei', r'wu\s?xi', r'wu\s?zhong', r'wu\s?zhou', r"xi'an", r'xi\s?an', r'xia\s?men', r'xiang\s?tan', r'xiang\s?yang', r'xia\s?ning', r'xian\s?tao', r'xian\s?yang', r'xiao\s?gan', r'shigatse',r'xi\s?ga\s?ze', r'xing\s?tai', r'xi\s?ning', r'xin\s?xiang', r'xin\s?yang', r'xin\s?yu', r'xin\s?zhou', r'xuan\s?cheng', r'xu\s?chang', r'xu\s?zhou', r"ya'an", r"yan'an", r'yan\s?cheng', r'yang\s?jiang', r'yang\s?quan', r'yang\s?zhou', r'yan\s?tai', r'yi\s?bin', r'yi\s?chang', r'yi\s?chun', r'yin\s?chuan', r'ying\s?kou', r'ying\s?tan', r'yi\s?wu', r'yi\s?xing', r'yi\s?yang', r'yong\s?zhou', r'yue\s?yang', r'yu\s?lin', r'yun\s?cheng', r'yun\s?fu', r'yu\s?xi', r'zao\s?zhuang', r'zhang\s?jia\s?jie', r'zhang\s?jia\s?kou', r'zhang\s?ye', r'zhang\s?zhou', r'zhan\s?jiang', r'zhao\s?qing', r'zhao\s?tong', r'zheng\s?zhou', r'zhen\s?jiang', r'zhong\s?shan', r'zhong\s?wei', r'zhou\s?kou', r'zhou\s?shan', r'zhu\s?hai', r'zhu\s?ma\s?dian', r'zhu\s?zhou', r'zi\s?bo', r'zi\s?gong', r'zi\s?yang', r'zun\s?yi')
    hanzi_cities = ('å®‰åº·',	'å®‰åº†',	'éå±±',	'å®‰é¡º',	'å®‰é˜³',	'ç™¾åŸ',	'ç™¾è‰²',	'ç™½å±±',	'ç™½é“¶',	'ä¿å®š',	'å®é¸¡',	'ä¿å±±',	'åŒ…å¤´',	'å·´å½¦æ·–å°”',	'å·´ä¸­',	'åŒ—æµ·',	'åŒ—äº¬',	'èšŒåŸ ',	'æœ¬æºª',	'æ»¨å·',	'åšä¹',	'äº³å·',	'æ²§å·',	'é•¿æ˜¥',	'å¸¸å¾·',	'é•¿æ²™',	'é•¿æ²»',	'å¸¸å·',	'å·¢æ¹–',	'æ½®å·',	'æ‰¿å¾·',	'æˆéƒ½',	'éƒ´å·',	'å˜‰ç¾©',	'èµ¤å³°',	'æ± å·',	'é‡åº†',	'å´‡å·¦',	'æ»å·',	'å¤§è¿',	'ä¸¹ä¸œ',	'å¤§åº†',	'å¤§åŒ',	'è¾¾å·',	'å¾·é˜³',	'å¾·å·',	'å®šè¥¿',	'ä¸œè',	'ä¸œè¥', 'æ©æ–½',	'é„‚å·',	'é˜²åŸæ¸¯', 'ä½›å±±', 'æŠšé¡º', 'é˜œæ–°',	'é˜œé˜³',	'ç¦å·',	'èµ£å·',	'å¹¿å®‰',	'å¹¿å…ƒ',	'å¹¿å·',	'è´µæ¸¯',	'æ¡‚æ—',	'è´µé˜³',	'å›ºåŸ',	'æµ·å£',	'å“ˆå¯†',	'é‚¯éƒ¸',	'æ­å·',	'æ±‰ä¸­',	'å“ˆå°”æ»¨',	'å“ˆå°”æ»¨',	'é¹¤å£',	'æ²³æ± ',	'åˆè‚¥',	'é¹¤å²—',	'é»‘æ²³',	'è¡¡æ°´',	'è¡¡é˜³',	'æ²³æº',	'èæ³½',	'è´ºå·',	'å‘¼å’Œæµ©ç‰¹',	'å‘¼å’Œæµ©ç‰¹',	'é¦™æ¸¯',	'æ–°ç«¹',	'æ·®å®‰',	'æ·®åŒ—',	'æ€€åŒ–',	'æ·®å—',	'é»„å†ˆ',	'é»„å±±',	'é»„çŸ³',	'æƒ å·',	'è‘«èŠ¦å²›',	'å‘¼ä¼¦è´å°”',	'æ¹–å·',	'å‰å®‰',	'åŠ æ ¼è¾¾å¥‡',	'ä½³æœ¨æ–¯',	'æ±Ÿé—¨',	'ç„¦ä½œ',	'å˜‰å…´',	'å˜‰å³ªå…³',	'æ­é˜³',	'å‰æ—',	'æµå—',	'é‡‘æ˜Œ',	'æ™‹åŸ',	'æ™¯å¾·é•‡',	'è†é—¨',	'è†å·',	'é‡‘å',	'æµå®',	'æ™‹ä¸­',	'é”¦å·',	'ä¹æ±Ÿ',	'é…’æ³‰',	'é¸¡è¥¿',	'æµæº',	'å¼€å°',	'é«˜é›„',	'å…‹æ‹‰ç›ä¾',	'å–€ä»€',	'å–€ä»€',	'åŸºéš†',	'æ˜†æ˜',	'æ˜†å±±',	'æ¥å®¾',	'è±èŠœ',	'å»ŠåŠ',	'å…°å·',	'ä¹å±±',	'æ‹‰è¨',	'è¿äº‘æ¸¯',	'èŠåŸ',	'è¾½é˜³',	'è¾½æº',	'ä¸½æ±Ÿ',	'ä¸´æ²§',	'ä¸´æ±¾',	'ä¸´å¤å·',	'ä¸´æ²‚',	'ä¸½æ°´',	'å…­ç›˜æ°´',	'æŸ³å·',	'é™‡å—',	'é¾™å²©',	'å¨„åº•',	'å…­å®‰',	'æ¼¯æ²³',	'æ´›é˜³',	'æ³¸å·',	'å•æ¢',	'é©¬éå±±',	'æ¾³é—¨',	'èŒ‚å',	'çœ‰å±±',	'æ¢…å·',	'ç»µé˜³',	'ç‰¡ä¸¹æ±Ÿ',	'é‚£æ›²',	'å—æ˜Œ',	'å—å……',	'å—äº¬',	'å—å®',	'å—å¹³',	'å—é€š',	'å—é˜³',	'å†…æ±Ÿ',	'é˜¿é‡Œåœ°åŒº ',	'å®æ³¢',	'å®å¾·',	'æ—èŠ',	'é„‚å°”å¤šæ–¯',	'é„‚å°”å¤šæ–¯',	'ç›˜é”¦',	'æ”€æèŠ±',	'å¹³é¡¶å±±',	'å¹³å‡‰',	'èä¹¡',	'å‡­ç¥¥',	'æ™®æ´±',	'è†ç”°',	'æ¿®é˜³',	'æ˜Œéƒ½',	'æ½œæ±Ÿ',	'é’å²›',	'åº†é˜³',	'æ¸…è¿œ',	'ç§¦çš‡å²›',	'é’¦å·',	'ç¼æµ·',	'é½é½å“ˆå°”',	'ä¸ƒå°æ²³',	'æ³‰å·',	'æ›²é–',	'è¡¢å·',	'æ—¥ç…§',	'ä¸‰é—¨å³¡',	'ä¸‰æ˜',	'ä¸‰äºš',	'ä¸Šæµ·',	'å•†æ´›',	'å•†ä¸˜',	'ä¸Šé¥¶',	'å±±å—',	'æ±•å¤´',	'æ±•å°¾',	'éŸ¶å…³',	'ç»å…´',	'é‚µé˜³',	'æ²ˆé˜³',	'æ·±åœ³',	'çŸ³å®¶åº„','åå °',	'çŸ³å˜´å±±',	'åŒé¸­å±±',	'æœ”å·',	'å››å¹³',	'æ¾åŸ',	'ç»¥åŒ–',	'é‚å®',	'éšå·',	'å®¿è¿',	'è‹å·',	'å¡”åŸ',	'æ³°å®‰',	'å°ä¸­',	'å°å—',	'å°åŒ—',	'å¤ªåŸ',	'å°å·',	'å”å±±',	'å¤©æ´¥',	'å¤©æ°´',	'è¥¿è—',	'é“å²­',	'é“œå·',	'é€šåŒ–',	'é€šè¾½',	'é“œé™µ',	'åé²ç•ª',	'ä¹Œå…°å¯Ÿ',	'ä¹Œé²æœ¨é½',	'ä¹Œé²æœ¨é½',	'æ½åŠ',	'å¨æµ·',	'æ¸­å—',	'æ–‡æ˜Œ',	'æ¸©å·',	'ä¹Œæµ·',	'æ­¦æ±‰',	'èŠœæ¹–',	'æ­¦å¨',	'æ— é”¡',	'å´å¿ ',	'æ¢§å·',	'è¥¿å®‰', 'è¥¿å®‰',	'å¦é—¨',	'æ¹˜æ½­',	'è¥„é˜³',	'å¤å®',	'ä»™æ¡ƒ',	'å’¸é˜³',	'å­æ„Ÿ',	'æ—¥å–€åˆ™',	'æ—¥å–€åˆ™',	'é‚¢å°',	'è¥¿å®',	'æ–°ä¹¡',	'ä¿¡é˜³',	'æ–°ä½™',	'å¿»å·',	'å®£åŸ',	'è®¸æ˜Œ',	'å¾å·',	'é›…å®‰',	'å»¶å®‰',	'ç›åŸ',	'é˜³æ±Ÿ',	'é˜³æ³‰',	'æ‰¬å·',	'çƒŸå°',	'å®œå®¾',	'å®œæ˜Œ',	'å®œæ˜¥',	'é“¶å·',	'è¥å£',	'é¹°æ½­',	'ä¹‰ä¹Œ', 'å®œå…´',	'ç›Šé˜³',	'æ°¸å·',	'å²³é˜³',	'æ¦†æ—',	'è¿åŸ',	'äº‘æµ®',	'ç‰æºª',	'æ£åº„',	'å¼ å®¶ç•Œ',	'å¼ å®¶å£',	'å¼ æ–',	'æ¼³å·',	'æ¹›æ±Ÿ',	'è‚‡åº†',	'æ˜­é€š',	'éƒ‘å·',	'é•‡æ±Ÿ',	'ä¸­å±±',	'ä¸­å«',	'å‘¨å£',	'èˆŸå±±',	'ç æµ·',	'é©»é©¬åº—',	'æ ªæ´²',	'æ·„åš',	'è‡ªè´¡',	'èµ„é˜³',	'éµä¹‰')
    # Double check lengths of these!!!
    # print(f'CITIES LEN: {len(py_cities)}')
    # print(f'HANZI LEN: {len(hanzi_cities)}')

    # Added regex to remove street and station names which are the same as city names - further modifications for Baoshan in Shanghai and the city of Baoshan
    cities = [c.replace(r'\s?', '') for c in py_cities if re.search(fr'\b{c}(?![,;\s](road|street|station|district|\sshang))\b', text, flags=re.I)]

    d={r'\bbj\b':'beijing', r'\bgz\b':'guangzhou', r'\bsz\b':'shenzhen'}
    for k,v in d.items():
        # if v not in cities and k in text:
        if v not in cities and re.search(k,text):
            cities.append(v)
            cities =  sorted(cities)

    
    for i,c in enumerate(hanzi_cities):
        py_city = py_cities[i].replace(r'\s?', '')
        if c in text and py_city not in cities:
            cities.append(py_city)



  # Check here for neg kws
#   'certificate', 'tefl','tesol' ,'ups' matches with groups
    neg_kws = ('scholarship','legalization','å–ç¾¤','ç©ºè¿','æµ·è¿','ç‰©æµ','dissertation','æ‰¹å‘','ç§Ÿèµ',
            'stipend','thesis','plagiarism','manufacturer','factory','battery','hsk','visa extension','åŒ…é‚®','early bird',
            'express delivery','dhl','fedex','ems','vpn','pinduoduo.com'
            
        )
   

    if any(w in text for w in neg_kws):
        job_types = []
        subjects = []
        is_job = False

        for w in neg_kws:
            if w in text:
                print(f'\033[35mNEGATIVE KEYWORD DETECTED: {w}\033[0m')

        # print(f'CITIES: {cities}')
        # print(f'JOB TYPES: {job_types}')
        # print(f'SUBJECTS: {subjects}')
        # print(f'IS_JOB: {is_job}')

        return [cities, job_types, subjects, is_job, trans]
  




    # Check for job types
    job_types = []

    teach = ('teach', 'tutor')
    if any(w in text for w in teach):
        job_types.append('teaching')

    school_type = ('primary school', 'middle school', 'high school', 'university', 'secondary school', 'public school', 'private school')
    for j in school_type:
        if j in text:
            job_types.append(j)

    if any(w in text for w in ('training center', 'training centre')):
        job_types.append('training centre')

    if 'online teach' in text:
        job_types.append('online teaching')

    # Looks for international with up to 3 words in the middle
    if re.search(r'international (\w+\s){0,3}school', text):
        job_types.append('international school')

    if any(w in text for w in ('kindergarten', 'kindergarden','å¹¼å„¿')):
        job_types.append('kindergarten')

    all_teaching_jobs = school_type + ('teaching', 'online teaching', 'international school', 'kindergarten')

    # 'recruit'

    # Other jobs types
    modelling = ('model', 'catwalk', 'èµ°ç§€', 'æ¨¡ç‰¹', 'å¥³æ¨¡', 'ç”·æ¨¡', 'mermaid', 'ç¾äººé±¼','æ‘©å¡','ç«¥æ¨¡')
    if any(w in text for w in modelling):
        job_types.append('model')
        if any(w in text for w in ('baby', 'babies')):
            job_types.append('baby modelling')
        if any(w in text for w in ('kid', 'kids','child','children','toddler','ç«¥æ¨¡')):
            job_types.append('child modelling')   

    # just æ‹ ??
    acting = ('actor', 'actress', 'filming', 'shoot', 'acting', 'æ‹æˆ', 'æ¼”æˆ', 'æ¼”å‘˜', 'æ‹æ‘„','æˆä»½','å¤§åˆ¶ä½œ')
    if any(w in text for w in acting):
        job_types.append('acting')

    dancing = ('dancing', 'dancer', 'bgo', 'gogo', 'èˆè¹ˆ', 'è·³èˆ', 'Ñ‚Ğ°Ğ½Ñ†Ğ¾Ñ€')
    if any(w in text for w in dancing):
        job_types.append('dancer')

    tiktok = ('tiktok', 'tik tok', 'douyin', 'dou yin', 'æŠ–éŸ³','live stream')
    if any(w in text for w in tiktok):
        job_types.append('tiktok')

    xiaohongshu = ('å°çº¢ä¹¦', 'xiao hong shu', 'xiaohongshu', 'little red book')
    if any(w in text for w in xiaohongshu):
        job_types.append('xiao hong shu')

    singer = ('singer', 'æ­Œæ‰‹', 'Ğ¿ĞµĞ²Ğ¸')
    if any(w in text for w in singer):
        job_types.append('singer')

    music = ('Ğ±ÑĞ½Ğ´', 'ä¹é˜Ÿ', 'musician', 'guitarist', 'drummer', 'piano', 'pianist')
    if any(w in text for w in music) or re.search(r'\bband\b',text):
        job_types.append('musician')

        
    travel = ('travel companion', 'ä¼´æ¸¸')
    if any(w in text for w in travel):
        job_types.append('travel companion')

    if re.search(r'\bdj\b', text):
        job_types.append('dj')

    karaoke = ('ktv', 'karaoke', 'ĞºĞ°Ñ€Ğ°Ğ¾ĞºĞµ')
    if any(w in text for w in karaoke):
        job_types.append('ktv')

    bar = ('drink with guests', ' bar ')
    if any(w in text for w in bar):
        job_types.append('bar work')

    if any(w in text for w in ('recording','å½•éŸ³')):
        job_types.append('recording')

    if 'voiceover' in text:
        job_types.append('voiceover')
    
    translate = ('translator', 'ç¿»è¯‘')
    if any(w in text for w in translate):
        job_types.append('translator')
    

    # t = ('')
    # if any(w in text for w in t):
    #     job_types.append('')

    job_types = sorted(job_types)



    subjects = [] 
    # Check for subjects only when job related to teaching
    if any(w in job_types for w in all_teaching_jobs):

        subject_list = ('drama', 'esl', 'ielts', 'toefl', 'toeic', 'maths?', 'mathematics', 'history', 'science', 'biology', 'physics', 'chemistry', 'geography', 'music', r'p\.?e\.?', 'physical education', 'philosophy', 'social studies', 'literature', 'economics', 'statistics', 'computer science', 'information technology', 'psychology', 'french art', 'german', 'spanish', 'japanese', 'korean', 'montessori')

        # capital_subs = ['esl', 'ielts', 'toefl', 'toeic']

        for s in subject_list:
            if re.search(fr'\b{s}\b', text):
                
                # if s in capital_subs:
                #     subjects.append(s.upper())
                #     continue
                if s == 'literature':
                    s = 'english literature'
            
                subjects.append(re.sub(r'[\\?]', '', s))

        # French language check
        if re.search(r'\bfrench(?!\sart)\b', text):
            subjects.append('french')

        # Art without French check
        if re.search(r'(?<!french)\sart\b', text):
            subjects.append('art')

        if re.search(fr'\benglish teacher\b', text):
            subjects.append('general english')

        subjects = sorted(subjects)

    is_job = True if job_types else False

    # print(f'\nWORD COUNT: {word_count}')
    # print(f'CITIES: {cities}')
    # print(f'JOB TYPES: {job_types}')
    # print(f'SUBJECTS: {subjects}')
    # print(f'IS_JOB: {is_job}')

    return [cities, job_types, subjects, is_job, trans]


# python manage.py shell

# text_parser(text)
# from test_parser import text_parser, run_script, run_script_by_pk


# def run_script():
#     from jobsboard.models import Job
#     job = Job.objects.order_by('?').first()
#     print('\033[31m**********************************\033[0m')
#     print(job.job_description)
#     print('\033[31m**********************************\033[0m')
#     print(text_parser(job.job_description))
#     print(f'JOB PK: {job.pk}')

# 4181
# def run_script_by_pk(pk):
#     from jobsboard.models import Job
#     job = Job.objects.get(pk=pk)
#     print('\033[31m**********************************\033[0m')
#     print(job.job_description)
#     print('\033[31m**********************************\033[0m')
#     print(text_parser(job.job_description))
#     print(f'JOB PK: {job.pk}')


# text_parser(text)